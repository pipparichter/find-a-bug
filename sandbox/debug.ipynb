{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: /home/prichter/Documents/find-a-bug/sandbox\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import requests\n",
    "import numpy as np \n",
    "import io\n",
    "import tqdm\n",
    "\n",
    "print('Current working directory:', os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233074/888517050.py:6: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  failures_df.append(pd.read_csv(os.path.join(LOG_DIR, file_name), comment='#'))\n",
      "/tmp/ipykernel_233074/888517050.py:6: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  failures_df.append(pd.read_csv(os.path.join(LOG_DIR, file_name), comment='#'))\n"
     ]
    }
   ],
   "source": [
    "LOG_DIR = os.path.join(os.getcwd(), '../scripts/log/')\n",
    "\n",
    "# Running into errors uploading certain annotations to the MariaDB database. \n",
    "failures_df = []\n",
    "for file_name in os.listdir(LOG_DIR):\n",
    "    failures_df.append(pd.read_csv(os.path.join(LOG_DIR, file_name), comment='#'))\n",
    "failures_df = pd.concat(failures_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1100 genome IDs failed to upload.\n"
     ]
    }
   ],
   "source": [
    "print(len(failures_df.genome_id.unique()), 'genome IDs failed to upload.')\n",
    "# Perhaps I should first make sure the files are actually present in the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "failing_genome_ids = failures_df['genome_id'].unique()\n",
    "np.savetxt('failing_genome_ids.txt', failing_genome_ids, fmt='%s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There doesnt seem to be any results for GCA_011364235.1. Length of results: 0\n",
      "There doesnt seem to be any results for GCF_015245355.1. Length of results: 0\n",
      "There doesnt seem to be any results for GCA_011364155.1. Length of results: 0\n",
      "There doesnt seem to be any results for GCA_011364265.1. Length of results: 0\n",
      "There doesnt seem to be any results for GCF_015244745.1. Length of results: 0\n",
      "There doesnt seem to be any results for GCA_011364225.1. Length of results: 0\n",
      "There doesnt seem to be any results for GCA_011364305.1. Length of results: 0\n"
     ]
    }
   ],
   "source": [
    "gene_ids_in_database_df = []\n",
    "for genome_id in failing_genome_ids:\n",
    "    url = f'http://microbes.gps.caltech.edu:8000/get/proteins_r207?genome_id[eq]{genome_id}'\n",
    "    result = requests.get(url).text \n",
    "    try:\n",
    "        gene_ids_in_database_df.append(pd.read_csv(io.StringIO(result)))\n",
    "    except:\n",
    "        print(f'There doesnt seem to be any results for {genome_id}. Length of results:', len(result))\n",
    "gene_ids_in_database_df = pd.concat(gene_ids_in_database_df)\n",
    "gene_ids_in_database_df.set_index('gene_id').to_csv('gene_ids_in_database.csv')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gene_ids_not_in_database_already_downloaded = np.loadtxt('gene_ids_not_in_database.txt', dtype=str)\n",
    "# gene_ids_to_check = [gene_id for gene_id in failures_df.gene_id.values if (gene_id not in gene_ids_not_in_database_already_downloaded)]\n",
    "# print(f'Already confirmed {len(gene_ids_not_in_database_already_downloaded)} missing genes.')\n",
    "\n",
    "gene_ids_not_in_database = []\n",
    "\n",
    "chunk_size = 50\n",
    "# Why are there duplicate gene IDs? Are some of the IDs not unique?\n",
    "gene_ids_to_check = failures_df.gene_id.unique().tolist()\n",
    "gene_ids_to_check = [gene_ids_to_check[i * chunk_size:(i + 1) * chunk_size] for i in range(len(gene_ids_to_check) // chunk_size + 1)]\n",
    "\n",
    "pbar = tqdm.tqdm(gene_ids_to_check, desc='Querying Find-A-Bug... Found 0 missing genes.')\n",
    "for chunk in pbar:\n",
    "    filter_ = 'gene_id[eq]' + '[or]'.join(chunk)\n",
    "    url = f'http://microbes.gps.caltech.edu:8000/get/proteins_r207?' + filter_\n",
    "\n",
    "    result = requests.get(url).text \n",
    "\n",
    "    if len(result) == 0:\n",
    "        print('No results returned!')\n",
    "        gene_ids_not_in_database += chunk\n",
    "        pbar.set_description(f'Querying Find-A-Bug... Found {len(gene_ids_not_in_database)} missing genes.')\n",
    "    else:\n",
    "        result_df = pd.read_csv(io.StringIO(result))\n",
    "        if len(result_df) < len(chunk):\n",
    "            print(f'Retrieved {len(result_df)} results, expected {len(chunk)}.')\n",
    "            gene_ids_not_in_database += [gene_id for gene_id in chunk if (gene_id not in result_df.gene_id)]\n",
    "            pbar.set_description(f'Querying Find-A-Bug... Found {len(gene_ids_not_in_database)} missing genes.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('gene_ids_not_in_database.txt', gene_ids_not_in_database, fmt='%s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "failures_df = failures_df[failures_df.gene_id.isin(gene_ids_not_in_database)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of genomes with failed genes: 28\n"
     ]
    }
   ],
   "source": [
    "print('Number of genomes with failed genes:', len(failures_df.genome_id.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['GCF_015244675.1', 'GCA_013140765.1', 'GCA_010032545.1', 'GCA_011364235.1', 'GCA_018401055.1', 'GCF_015694425.1', 'GCF_015245355.1', 'GCA_001779505.1', 'GCA_018608425.1', 'GCA_011364155.1', 'GCA_003157385.1', 'GCF_002909445.1', 'GCA_011364525.1', 'GCA_905182715.1', 'GCA_011364265.1', 'GCA_900545805.1', 'GCF_000709085.1', 'GCF_015244745.1', 'GCA_012518835.1', 'GCA_017467305.1', 'GCF_015265435.1', 'GCF_003946115.1', 'GCA_011364225.1', 'GCA_002313895.1', 'GCF_001675285.1', 'GCA_011364305.1', 'GCF_902499045.1', 'GCA_011364105.1']\n"
     ]
    }
   ],
   "source": [
    "# for genome_id in failures_df.genome_id.unique():\n",
    "#     print(genome_id)\n",
    "\n",
    "# \"is present\" means it is in the source directory (proteins_aa)\n",
    "# GCF_015244675.1 is present \n",
    "# GCF_015244675.1 is present\n",
    "# GCA_010032545.1 is present\n",
    "# GCA_011364235.1 is present\n",
    "# GCA_018401055.1 is present\n",
    "# GCF_015694425.1 is present\n",
    "\n",
    "genome_ids = [f\"\\'{genome_id}\\'\" for genome_id in failures_df.genome_id.unique()]\n",
    "print(f\"[{', '.join(genome_ids)}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
